{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from math import log2\n",
    "from nltk import FreqDist\n",
    "from numpy.linalg import svd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized words\n",
      "\n",
      "[['This', 'is', 'the', 'first', 'book'], ['This', 'book', 'is', 'the', 'second', 'book'], ['And', 'this', 'is', 'the', 'third', 'one'], ['Is', 'this', 'the', 'first', 'book']]\n"
     ]
    }
   ],
   "source": [
    "document = ['This is the first book','This book is the second book','And this is the third one', 'Is this the first book']\n",
    "\n",
    "tokenized_words = [word_tokenize(sent) for sent in document]\n",
    "print(\"Tokenized words\\n\")\n",
    "print(tokenized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower cased words\n",
      "\n",
      "[['this', 'is', 'the', 'first', 'book'], ['this', 'book', 'is', 'the', 'second', 'book'], ['and', 'this', 'is', 'the', 'third', 'one'], ['is', 'this', 'the', 'first', 'book']]\n"
     ]
    }
   ],
   "source": [
    "lowered_words = [[w.lower() for w in word] for word in tokenized_words]\n",
    "print(\"Lower cased words\\n\")\n",
    "print(lowered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'first',\n",
       " 'book',\n",
       " 'this',\n",
       " 'book',\n",
       " 'is',\n",
       " 'the',\n",
       " 'second',\n",
       " 'book',\n",
       " 'and',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'third',\n",
       " 'one',\n",
       " 'is',\n",
       " 'this',\n",
       " 'the',\n",
       " 'first',\n",
       " 'book']"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [w for words in lowered_words for w in words]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first', 'is', 'the', 'one', 'this', 'and', 'third', 'book', 'second']\n"
     ]
    }
   ],
   "source": [
    "#vocab = list(sorted(set(tokens)))\n",
    "vocab = list(set(tokens))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrences = OrderedDict((name, OrderedDict((name, 0) for name in vocab)) for name in vocab)\n",
    "\n",
    "for l in lowered_words:\n",
    "    for i in range(len(l)):\n",
    "        for item in l[:i] + l[i + 1:]:\n",
    "                occurrences[l[i]][item] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the first book',\n",
       " 'This book is the second book',\n",
       " 'And this is the third one',\n",
       " 'Is this the first book']"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/c\t| first\tis\tthe\tone\tthis\tand\tthird\tbook\tsecond\n",
      "--------------------------------------------------------------------------------------\n",
      "first\t| 0\t2\t2\t0\t2\t0\t0\t2\t0\n",
      "is\t| 2\t0\t4\t1\t4\t1\t1\t4\t1\n",
      "the\t| 2\t4\t0\t1\t4\t1\t1\t4\t1\n",
      "one\t| 0\t1\t1\t0\t1\t1\t1\t0\t0\n",
      "this\t| 2\t4\t4\t1\t0\t1\t1\t4\t1\n",
      "and\t| 0\t1\t1\t1\t1\t0\t1\t0\t0\n",
      "third\t| 0\t1\t1\t1\t1\t1\t0\t0\t0\n",
      "book\t| 2\t4\t4\t0\t4\t0\t0\t2\t2\n",
      "second\t| 0\t1\t1\t0\t1\t0\t0\t2\t0\n"
     ]
    }
   ],
   "source": [
    "print('w/c\\t|', '\\t'.join(occurrences.keys()))\n",
    "print(\"--------------------------------------------------------------------------------------\")\n",
    "co_occurances = []\n",
    "for name, values in occurrences.items():\n",
    "    co_occurances.append(values.values())\n",
    "    #print(name, ' '.join(str(i) for i in values.values()))\n",
    "    print(name + \"\\t|\",'\\t'.join(str(i) for i in values.values()),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first', 'is', 'the', 'one', 'this', 'and', 'third', 'book', 'second']\n"
     ]
    }
   ],
   "source": [
    "co_words = list(occurrences.keys())\n",
    "print(co_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the first book',\n",
       " 'This book is the second book',\n",
       " 'And this is the third one',\n",
       " 'Is this the first book']"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for name, values in occurrences.items():\n",
    "    for i in range(len(co_words)):\n",
    "        a.append(values.popitem())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = []\n",
    "for i in range(len(a)):\n",
    "    mat.append(a[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 1 0 0 2 0]\n",
      " [2 4 4 0 4 0 0 2 2]\n",
      " [0 1 1 1 1 1 0 0 0]\n",
      " [0 1 1 1 1 0 1 0 0]\n",
      " [2 4 4 1 0 1 1 4 1]\n",
      " [0 1 1 0 1 1 1 0 0]\n",
      " [2 4 0 1 4 1 1 4 1]\n",
      " [2 0 4 1 4 1 1 4 1]\n",
      " [0 2 2 0 2 0 0 2 0]]\n"
     ]
    }
   ],
   "source": [
    "mat = np.reshape(b,(9,9))\n",
    "print(mat.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqDist = FreqDist(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'this': 4, 'is': 4, 'the': 4, 'book': 4, 'first': 2, 'second': 1, 'and': 1, 'third': 1, 'one': 1})"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n = np.shape(mat)\n",
    "\n",
    "pmi_mat = np.zeros((m,n))\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        if mat[i][j] == 0:\n",
    "            pmi_mat[i][j] = 0\n",
    "        else:\n",
    "            w = co_words[i]\n",
    "            c = co_words[j]\n",
    "            #print(freqDist[w]*freqDist[c])\n",
    "            pmi = log2((mat[i][j]*m)/(freqDist[w]*freqDist[c]))\n",
    "            #print(int(mat[i][j]))\n",
    "            if pmi <= 0:\n",
    "                pmi_mat[i][j] = 0\n",
    "            else:\n",
    "                pmi_mat[i][j] = pmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.      , 1.169925, 0.      , 0.      , 1.169925, 0.      ,\n",
       "        3.169925, 1.169925, 0.      ],\n",
       "       [0.169925, 1.169925, 0.      , 1.169925, 1.169925, 1.169925,\n",
       "        3.169925, 0.      , 2.169925],\n",
       "       [0.169925, 1.169925, 0.      , 1.169925, 1.169925, 1.169925,\n",
       "        0.      , 1.169925, 2.169925],\n",
       "       [0.      , 0.      , 1.169925, 3.169925, 1.169925, 0.      ,\n",
       "        3.169925, 1.169925, 0.      ],\n",
       "       [0.169925, 1.169925, 0.      , 1.169925, 0.      , 1.169925,\n",
       "        3.169925, 1.169925, 2.169925],\n",
       "       [0.      , 0.      , 1.169925, 0.      , 1.169925, 3.169925,\n",
       "        3.169925, 1.169925, 0.      ],\n",
       "       [0.      , 0.      , 0.      , 3.169925, 1.169925, 3.169925,\n",
       "        3.169925, 1.169925, 0.      ],\n",
       "       [1.169925, 0.169925, 0.      , 0.      , 1.169925, 0.      ,\n",
       "        3.169925, 1.169925, 2.169925],\n",
       "       [0.      , 2.169925, 0.      , 0.      , 1.169925, 0.      ,\n",
       "        3.169925, 1.169925, 0.      ]])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.23661990e+00  1.15916690e+00  1.43898218e+00 -1.16999633e-16\n",
      "   3.94278509e-01  1.33175386e-01 -1.10404602e-15 -2.29549020e-01\n",
      "   1.96641933e-01]\n",
      " [-4.15870847e+00  8.20790224e-01 -9.85420005e-01  1.50491764e-15\n",
      "  -1.39166567e-01 -7.45321610e-01 -8.27261902e-01  2.48260470e-01\n",
      "   1.72940166e-02]\n",
      " [-2.05397762e+00  2.40159111e-01 -2.32118515e+00 -6.26794622e-17\n",
      "   1.03145148e+00  9.20987643e-01  2.83200771e-16  6.25360573e-02\n",
      "   2.54845385e-02]\n",
      " [-4.08962236e+00 -1.17276404e+00  7.55502194e-01 -2.24147546e+00\n",
      "  -3.44290246e-01  4.44375202e-01  1.97654273e-15  4.37706589e-01\n",
      "  -6.93133590e-03]\n",
      " [-4.15870847e+00  8.20790224e-01 -9.85420005e-01 -4.21662479e-16\n",
      "  -1.39166567e-01 -7.45321610e-01  8.27261902e-01  2.48260470e-01\n",
      "   1.72940166e-02]\n",
      " [-4.08962236e+00 -1.17276404e+00  7.55502194e-01  2.24147546e+00\n",
      "  -3.44290246e-01  4.44375202e-01  2.33373409e-15  4.37706589e-01\n",
      "  -6.93133590e-03]\n",
      " [-4.98517809e+00 -2.71109327e+00 -2.83027789e-01  1.52897147e-15\n",
      "   2.47231321e-01 -3.30376341e-01 -3.15656775e-15 -6.55761442e-01\n",
      "  -1.71933954e-02]\n",
      " [-3.60603026e+00  1.87360098e+00 -3.57972281e-01  8.35550278e-17\n",
      "  -1.30522508e+00  5.77990536e-01 -2.13392184e-15 -4.57585479e-01\n",
      "  -5.47542234e-02]\n",
      " [-3.41768270e+00  1.54473862e+00  1.41286916e+00 -1.51982617e-16\n",
      "   1.18589756e+00 -5.72011875e-02  1.01049685e-17 -3.25733061e-02\n",
      "  -1.44188574e-01]]\n"
     ]
    }
   ],
   "source": [
    "u,s,v = svd(pmi_mat)\n",
    "word_mat = np.matmul(u,np.diag(s))\n",
    "print(word_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.23661990e+00  1.15916690e+00  1.43898218e+00 -1.16999633e-16\n",
      "   3.94278509e-01  1.33175386e-01 -1.10404602e-15 -2.29549020e-01\n",
      "   1.96641933e-01]\n",
      " [-4.15870847e+00  8.20790224e-01 -9.85420005e-01  1.50491764e-15\n",
      "  -1.39166567e-01 -7.45321610e-01 -8.27261902e-01  2.48260470e-01\n",
      "   1.72940166e-02]\n",
      " [-2.05397762e+00  2.40159111e-01 -2.32118515e+00 -6.26794622e-17\n",
      "   1.03145148e+00  9.20987643e-01  2.83200771e-16  6.25360573e-02\n",
      "   2.54845385e-02]\n",
      " [-4.08962236e+00 -1.17276404e+00  7.55502194e-01 -2.24147546e+00\n",
      "  -3.44290246e-01  4.44375202e-01  1.97654273e-15  4.37706589e-01\n",
      "  -6.93133590e-03]\n",
      " [-4.15870847e+00  8.20790224e-01 -9.85420005e-01 -4.21662479e-16\n",
      "  -1.39166567e-01 -7.45321610e-01  8.27261902e-01  2.48260470e-01\n",
      "   1.72940166e-02]\n",
      " [-4.08962236e+00 -1.17276404e+00  7.55502194e-01  2.24147546e+00\n",
      "  -3.44290246e-01  4.44375202e-01  2.33373409e-15  4.37706589e-01\n",
      "  -6.93133590e-03]\n",
      " [-4.98517809e+00 -2.71109327e+00 -2.83027789e-01  1.52897147e-15\n",
      "   2.47231321e-01 -3.30376341e-01 -3.15656775e-15 -6.55761442e-01\n",
      "  -1.71933954e-02]\n",
      " [-3.60603026e+00  1.87360098e+00 -3.57972281e-01  8.35550278e-17\n",
      "  -1.30522508e+00  5.77990536e-01 -2.13392184e-15 -4.57585479e-01\n",
      "  -5.47542234e-02]\n",
      " [-3.41768270e+00  1.54473862e+00  1.41286916e+00 -1.51982617e-16\n",
      "   1.18589756e+00 -5.72011875e-02  1.01049685e-17 -3.25733061e-02\n",
      "  -1.44188574e-01]]\n"
     ]
    }
   ],
   "source": [
    "s = np.diag(s)\n",
    "word_mat = np.matmul(u,s[:,0:10])\n",
    "print(word_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
